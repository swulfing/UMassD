knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# library(pak)
# library(devtools)
# pak::pkg_install("timjmiller/wham")
# devtools::install_github("lichengxue/whamMSE", dependencies=TRUE)
# devtools::install_github("NOAA-EDAB/ecodata", dependencies=TRUE, build = FALSE)
library(wham)
library(whamMSE)
library(ecodata)
library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
gb_dat <- read_asap3_dat("ASAPfiles_5.14Pull/GBK.DAT")
input <- prepare_wham_input(gb_dat)
year_start  <- 1  # starting year in the burn-in period
year_end    <- 20  # end year in the burn-in period
MSE_years   <- 3     # number of years in the feedback loop
# Note: no need to include MSE_years in simulation-estimation
info <- generate_basic_info(n_stocks = input$data$n_stocks,
n_regions = input$data$n_regions,
n_indices = input$data$n_indices,
n_fleets = input$data$n_fleets,
n_seasons = input$data$n_seasons,
base.years = year_start:year_end,
n_feedback_years = MSE_years,
life_history = "medium", # Not sure if we're keeping this
n_ages = input$data$n_ages)
basic_info = info$basic_info # collect basic information
catch_info = info$catch_info # collect fleet catch information
index_info = info$index_info # collect survey information
F_info = info$F # collect fishing information
n_stocks  <- as.integer(basic_info['n_stocks'])
n_regions <- as.integer(basic_info['n_regions'])
n_fleets  <- as.integer(basic_info['n_fleets'])
n_indices <- as.integer(basic_info['n_indices'])
n_ages    <- as.integer(basic_info['n_ages'])
# Selectivity Configuration - ALEX CODE
sel2=list(
model=c("age-specific",
"logistic","logistic","logistic"),
re = c("ar1_y","none","none","none"),
initial_pars=list(
c(0.1,0.25,0.5,1,1,1), # Commercial fleet
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3)), # DFO survey
fix_pars = list(
c(6),
c(NULL),
c(NULL),
c(NULL))
)
# CHENG SELECTIVITY
# fleet_pars <- c(5,1)
# index_pars <- c(2,1)
# sel <- list(model=rep("logistic",n_fleets+n_indices),
#             initial_pars=c(rep(list(fleet_pars),n_fleets),rep(list(index_pars),n_indices)))
# M Configuration
M <- list(model="constant",initial_means=array(c(0.57, 0.33, 0.26, 0.23, 0.22, 0.22), dim = c(n_stocks,n_regions,n_ages)))
sigma        <- "rec+1"
re_cor       <- "iid"
ini.opt      <- "equilibrium"
sigma_vals   <-  array(0.5, dim = c(n_stocks, n_regions, n_ages)) # NAA sigma
# NAA config
NAA_re <- list(N1_model=rep(ini.opt,n_stocks),
sigma=rep(sigma,n_stocks),
cor=rep(re_cor,n_stocks),
recruit_model = 3,  # rChanged from ALEX code
sigma_vals = sigma_vals) # NAA_where must be specified in basic_info!
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
random = input_NoEcov$random # check what processes are random effects
input_NoEcov$random = NULL # so inner optimization won't change simulated RE
om <- fit_wham(input_NoEcov, do.fit = F, do.brps = T, MakeADFun.silent = TRUE)
om
View(om)
om <- fit_wham(input_NoEcov, do.fit = F, do.brps = T, MakeADFun.silent = TRUE, do.retro = FALSE, do.osa = FALSE)
om_with_data <- update_om_fn(om, seed = 123, random = random)
check_convergence(om)
View(om)
knitr::opts_chunk$set(echo = FALSE)
library(wham)
library(Hmisc)
library(mvtnorm)
library(here)
library(tidyverse)
library(ggdist)
#library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
gb_dat <- read_asap3_dat(here("YT_proj/ASAPfiles_5.14Pull/GBK.DAT"))
input <- prepare_wham_input(gb_dat)
start_year <- gb_dat[[1]]$dat$year1
end_year <- gb_dat[[1]]$dat$year1 + gb_dat[[1]]$dat$n_years
data.years <- start_year:(end_year-1)
harvest <- rowSums(gb_dat[[1]][["dat"]][["CAA_mats"]][[1]])
#harvest <- harvest[-c(1:28)]
index_all <- matrix(, nrow = (88), ncol = 7)
#NOTE: IM JUST ADDING ALL THE INDICES TOGETHER AND MAKING ALL 0s -> NAs. NO IDEA IF IM SUPPOSED TO DO THAT
for(i in 1:length(gb_dat[[1]][["dat"]][["IAA_mats"]])){
index_fill <- gb_dat[[1]][["dat"]][["IAA_mats"]][[i]]
index_fill <- index_fill[,-1] # index_fill <- index_fill[-c(1:28),-1]
index_all[,i] <- rowSums(index_fill)
}
index <- rowSums(index_all)
index[index == 0] <- NA
plot(data.years,index, pch=19,xlab="Year", ylim = c(0,max(harvest))) +
lines(data.years,harvest,lty=2,lwd=2)
knitr::opts_chunk$set(echo = FALSE)
library(wham)
library(Hmisc)
library(mvtnorm)
library(here)
library(tidyverse)
library(ggdist)
#library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
gb_dat <- read_asap3_dat(here("YT_proj/ASAPfiles_5.14Pull/GBK.DAT"))
input <- prepare_wham_input(gb_dat)
start_year <- gb_dat[[1]]$dat$year1
end_year <- gb_dat[[1]]$dat$year1 + gb_dat[[1]]$dat$n_years
data.years <- start_year:(end_year-1)
harvest <- rowSums(gb_dat[[1]][["dat"]][["CAA_mats"]][[1]])
#harvest <- harvest[-c(1:28)]
index_all <- matrix(, nrow = (88), ncol = 7)
#NOTE: IM JUST ADDING ALL THE INDICES TOGETHER AND MAKING ALL 0s -> NAs. NO IDEA IF IM SUPPOSED TO DO THAT
for(i in 1:length(gb_dat[[1]][["dat"]][["IAA_mats"]])){
index_fill <- gb_dat[[1]][["dat"]][["IAA_mats"]][[i]]
index_fill <- index_fill[,-1] # index_fill <- index_fill[-c(1:28),-1]
index_all[,i] <- rowSums(index_fill)
}
index <- rowSums(index_all)
index[index == 0] <- NA
plot(data.years,index, pch=19,xlab="Year", ylim = c(0,max(harvest))) +
lines(data.years,harvest,lty=2,lwd=2)
# Logistic Production
schaefer <- function(B,C,K,r) {
#function schaefer takes the current biomass, a catch,
#and the model parameters to compute next year's biomass
res <- B + B * r * (1 - B/K) - C
return(max(0.001,res)) # we add a constraint to prevent negative biomass
}
# Biomass Projection
dynamics <- function(pars,C,yrs) {
# dynamics takes the model parameters, the time series of catch,
# & the yrs to do the projection over
# first extract the parameters from the pars vector (we estimate K in log-space)
K <- exp(pars[1])
r <- exp(pars[2])
# find the total number of years
nyr <- length(C) + 1
# if the vector of years was not supplied we create
# a default to stop the program crashing
if (missing(yrs)) yrs <- 1:nyr
#set up the biomass vector
B <- numeric(nyr)
#intialize biomass at carrying capacity
B[1] <- K
# project the model forward using the schaefer model
for (y in 2:nyr) {
B[y] <- schaefer(B[y-1],C[y-1],K,r)
}
#return the time series of biomass
return(B[yrs])
#end function dynamics
}
# function to calculate the negative log-likelihood
nll <- function(pars,C,U) { #this function takes the parameters, the catches, and the index data
sigma <- exp(pars[3]) # additional parameter, the standard deviation of the observation error
B <- dynamics(pars,C) #run the biomass dynamics for this set of parameters
Uhat <- B #calculate the predicted biomass index - here we assume an unbiased absolute biomass estimate
output <- -sum(dnorm(log(U),log(Uhat),sigma,log=TRUE),na.rm=TRUE) #calculate the negative log-likelihood
return(output)
#end function nll
}
assess <- function(catch,index,calc.vcov=FALSE,pars.init) {
# assess takes catch and index data, initial values for the parameters,
# and a flag saying whether to compute uncertainty estimates for the model parameters
#fit model
# optim runs the function nll() repeatedly with differnt values for the parameters,
# to find the values that give the best fit to the index data
res <- optim(pars.init,nll,C=catch,U=index,hessian=TRUE)
# store the output from the model fit
output <- list()
output$pars <- res$par
output$biomass <- dynamics(res$par,catch)
output$convergence <- res$convergence
output$nll <- res$value
if (calc.vcov)
output$vcov <- solve(res$hessian)
return(output)
#end function assess
}
# ONLY RUNS IF YOU HAVE A VERY HIGH CARRYING CAPACITY IDK
ini.parms <- c(log(999999), log(0.1), log(0.3)) # log(K), log(r), log(sigma)
redfish <- assess(harvest,index,calc.vcov=TRUE,ini.parms) # SUPPOSED TO BE calc.vcov = TRUE but running into error so going to skip for now
redfish
biomass.mle <- redfish$biomass
print(biomass.mle)
pars.mle <- redfish$pars
print(exp(pars.mle))
# Generate list of plausable alternatives
#define the number of iterations for the MSE
niter <- 200
#set up a storage matrix for our alternative parameter sets
pars.iter <- matrix(NA,nrow = niter, ncol=3)
colnames(pars.iter) <- c("log_K","log_r","log_sigma")
# generate the sets of parameter values
for (i in 1:niter) {
pars.iter[i,] <- mvtnorm::rmvnorm(1, mean = redfish$pars,
sigma = redfish$vcov)
}
# Now generate replicate model outputs
biomass.iter <- data.frame()
for (i in 1:niter) {
#here we calculate the biomass trajectory for each of the above sampled parameter vectors
biomass.iter <- rbind(biomass.iter,
data.frame(year = seq(min(data.years),
max(data.years)+1),
biomass = dynamics(pars.iter[i,], harvest),
iter = i))
}
biomass.iter <- biomass.iter
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# library(pak)
# library(devtools)
# pak::pkg_install("timjmiller/wham")
# devtools::install_github("lichengxue/whamMSE", dependencies=TRUE)
# devtools::install_github("NOAA-EDAB/ecodata", dependencies=TRUE, build = FALSE)
library(wham)
library(whamMSE)
library(ecodata)
library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
SNE_dat <- read_asap3_dat("ASAPfiles_5.14Pull/sne_asap_2023_RT.DAT")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# library(pak)
# library(devtools)
# pak::pkg_install("timjmiller/wham")
# devtools::install_github("lichengxue/whamMSE", dependencies=TRUE)
# devtools::install_github("NOAA-EDAB/ecodata", dependencies=TRUE, build = FALSE)
library(wham)
library(whamMSE)
library(ecodata)
library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
SNE_dat <- read_asap3_dat("ASAPfiles_5.14Pull/SNEMA_split.DAT")
input <- prepare_wham_input(SNE_dat)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# library(pak)
# library(devtools)
# pak::pkg_install("timjmiller/wham")
# devtools::install_github("lichengxue/whamMSE", dependencies=TRUE)
# devtools::install_github("NOAA-EDAB/ecodata", dependencies=TRUE, build = FALSE)
library(wham)
library(whamMSE)
library(ecodata)
library(dplyr)
write.dir <- "C:/Users/swulfing/Documents/GitHub/UMassD/YT_proj"
setwd(write.dir)
SNE_dat <- read_asap3_dat("ASAPfiles_5.14Pull/SNEMA_split.DAT")
input <- prepare_wham_input(SNE_dat)
year_start  <- 1  # starting year in the burn-in period
year_end    <- 20  # end year in the burn-in period
MSE_years   <- 3     # number of years in the feedback loop
# Note: no need to include MSE_years in simulation-estimation
info <- generate_basic_info(n_stocks = input$data$n_stocks,
n_regions = input$data$n_regions,
n_indices = input$data$n_indices,
n_fleets = input$data$n_fleets,
n_seasons = input$data$n_seasons,
base.years = year_start:year_end,
n_feedback_years = MSE_years,
life_history = "medium", # Not sure if we're keeping this
n_ages = input$data$n_ages)
basic_info = info$basic_info # collect basic information
catch_info = info$catch_info # collect fleet catch information
index_info = info$index_info # collect survey information
F_info = info$F # collect fishing information
n_stocks  <- as.integer(basic_info['n_stocks'])
n_regions <- as.integer(basic_info['n_regions'])
n_fleets  <- as.integer(basic_info['n_fleets'])
n_indices <- as.integer(basic_info['n_indices'])
n_ages    <- as.integer(basic_info['n_ages'])
# Selectivity Configuration - ALEX CODE
sel2=list(
model=c("age-specific",
"logistic","logistic","logistic"),
re = c("ar1_y","none","none","none"),
initial_pars=list(
c(0.1,0.25,0.5,1,1,1), # Commercial fleet
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3)), # DFO survey
fix_pars = list(
c(6),
c(NULL),
c(NULL),
c(NULL))
)
# CHENG SELECTIVITY
# fleet_pars <- c(5,1)
# index_pars <- c(2,1)
# sel <- list(model=rep("logistic",n_fleets+n_indices),
#             initial_pars=c(rep(list(fleet_pars),n_fleets),rep(list(index_pars),n_indices)))
# M Configuration
M <- list(model="constant",initial_means=array(c(0.57, 0.33, 0.26, 0.23, 0.22, 0.22), dim = c(n_stocks,n_regions,n_ages)))
sigma        <- "rec+1"
re_cor       <- "iid"
ini.opt      <- "equilibrium"
sigma_vals   <-  array(0.5, dim = c(n_stocks, n_regions, n_ages)) # NAA sigma
# NAA config
NAA_re <- list(N1_model=rep(ini.opt,n_stocks),
sigma=rep(sigma,n_stocks),
cor=rep(re_cor,n_stocks),
recruit_model = 3,  # rChanged from ALEX code
sigma_vals = sigma_vals) # NAA_where must be specified in basic_info!
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
View(SNE_dat)
# Selectivity Configuration - ALEX CODE
sel2=list(
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
random = input_NoEcov$random # check what processes are random effects
random = input_NoEcov$random # check what processes are random effects
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
# Selectivity Configuration - ALEX CODE
sel2=list(
model=c("age-specific",
"logistic","logistic","logistic","logistic"),
re = c("ar1_y","none","none","none","none"),
initial_pars=list(
c(0.1,0.25,0.5,1,1,1), # Commercial fleet
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3),
c(2,0.3)), # DFO survey
fix_pars = list(
c(6),
c(NULL),
c(NULL),
c(NULL),
c(NULL))
)
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
info$index_info
# Selectivity Configuration - ALEX CODE
sel2=list(
model=c("age-specific",
"logistic","logistic","logistic","logistic","logistic","logistic","logistic","logistic"),
re = c("ar1_y","none","none","none","none","none","none","none","none"),
initial_pars=list(
c(0.1,0.25,0.5,1,1,1), # Commercial fleet
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3),
c(2,0.3),
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3),
c(2,0.3)), # DFO survey
fix_pars = list(
c(6),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL))
)
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
# Selectivity Configuration - ALEX CODE
sel2=list(
model=c("age-specific",
"logistic","logistic","logistic","logistic","logistic","logistic","logistic","logistic","logistic"),
re = c("ar1_y","none","none","none","none","none","none","none","none","none"),
initial_pars=list(
c(0.1,0.25,0.5,1,1,1), # Commercial fleet
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3),
c(2,0.3),
c(2,0.3), # Spring NEFSC
c(2,0.3), # Fall NEFSC
c(2,0.3),
c(2,0.3),
c(2,0.3)), # DFO survey
fix_pars = list(
c(6),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL),
c(NULL))
)
input_NoEcov <- prepare_wham_input(basic_info = basic_info,
selectivity = sel2,
M = M,
NAA_re = NAA_re,
catch_info = catch_info,
index_info = index_info,
F = F_info)
random = input_NoEcov$random # check what processes are random effects
input_NoEcov$random = NULL # so inner optimization won't change simulated RE
om <- fit_wham(input_NoEcov, do.fit = F, do.brps = T, MakeADFun.silent = TRUE, do.retro = FALSE, do.osa = FALSE) #Changing do.retro and do.osa as per SGaichas email
check_convergence(om)
View(NAA_re)
View(om)
